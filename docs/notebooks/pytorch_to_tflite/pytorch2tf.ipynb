{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Converting to TensorFlow Lite using pytorch_to_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting https://github.com/gmalivenko/pytorch2keras/archive/refs/heads/master.zip (from -r requirements.txt (line 13))\n",
      "  Downloading https://github.com/gmalivenko/pytorch2keras/archive/refs/heads/master.zip\n",
      "\u001b[K     - 54 kB 1.3 MB/ss\n",
      "\u001b[?25hRequirement already satisfied: jupyter in /usr/local/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: torch==1.12.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.12.0)\n",
      "Requirement already satisfied: torchvision==0.13.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.13.0)\n",
      "Requirement already satisfied: onnx in /usr/local/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: onnxruntime in /usr/local/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.14.1)\n",
      "Requirement already satisfied: tensorflow in /usr/local/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (2.12.0rc0)\n",
      "Requirement already satisfied: onnx2tf in /usr/local/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.7.21)\n",
      "Requirement already satisfied: onnx-graphsurgeon in /usr/local/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (0.3.26)\n",
      "Requirement already satisfied: sng4onnx in /usr/local/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (1.0.1)\n",
      "Requirement already satisfied: keras in /usr/local/anaconda3/lib/python3.8/site-packages (from pytorch2keras==0.2.4->-r requirements.txt (line 13)) (2.12.0rc1)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/lib/python3.8/site-packages (from pytorch2keras==0.2.4->-r requirements.txt (line 13)) (1.22.4)\n",
      "Requirement already satisfied: onnx2keras in /usr/local/anaconda3/lib/python3.8/site-packages (from pytorch2keras==0.2.4->-r requirements.txt (line 13)) (0.0.24)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/anaconda3/lib/python3.8/site-packages (from torch==1.12.0->-r requirements.txt (line 2)) (4.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.8/site-packages (from torchvision==0.13.0->-r requirements.txt (line 3)) (2.25.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from torchvision==0.13.0->-r requirements.txt (line 3)) (8.2.0)\n",
      "Requirement already satisfied: notebook in /usr/local/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 1)) (6.3.0)\n",
      "Requirement already satisfied: qtconsole in /usr/local/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 1)) (5.0.3)\n",
      "Requirement already satisfied: ipykernel in /usr/local/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 1)) (6.15.2)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 1)) (7.6.3)\n",
      "Requirement already satisfied: nbconvert in /usr/local/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 1)) (6.0.7)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 1)) (6.4.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx->-r requirements.txt (line 4)) (3.20.3)\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime->-r requirements.txt (line 5)) (20.9)\n",
      "Requirement already satisfied: sympy in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime->-r requirements.txt (line 5)) (1.8)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime->-r requirements.txt (line 5)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime->-r requirements.txt (line 5)) (2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (0.4.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (13.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (0.24.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (3.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (1.51.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0rc0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 6)) (2.12.0rc0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 6)) (0.36.2)\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow->-r requirements.txt (line 6)) (1.6.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (2.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (4.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (4.11.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.0->-r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.0->-r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.0->-r requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->torchvision==0.13.0->-r requirements.txt (line 3)) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from coloredlogs->onnxruntime->-r requirements.txt (line 5)) (10.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (6.1.12)\n",
      "Requirement already satisfied: appnope in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (1.5.1)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (5.3.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (0.1.6)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (20.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (6.1)\n",
      "Requirement already satisfied: psutil in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (5.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (3.0.17)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: backcall in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (2.14.0)\n",
      "Requirement already satisfied: stack-data in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: decorator in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (5.0.6)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r requirements.txt (line 1)) (4.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/anaconda3/lib/python3.8/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.2.5)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 1)) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 1)) (5.1.3)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 1)) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 1)) (0.17.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 1)) (0.9.4)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 1)) (20.1.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 1)) (2.11.3)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 1)) (0.10.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 1)) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /usr/local/anaconda3/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter->-r requirements.txt (line 1)) (2.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/anaconda3/lib/python3.8/site-packages (from jinja2->notebook->jupyter->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: bleach in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (1.4.3)\n",
      "Requirement already satisfied: testpath in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.4.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.5.13)\n",
      "Requirement already satisfied: defusedxml in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: webencodings in /usr/local/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from packaging->onnxruntime->-r requirements.txt (line 5)) (2.4.7)\n",
      "Requirement already satisfied: qtpy in /usr/local/anaconda3/lib/python3.8/site-packages (from qtconsole->jupyter->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: asttokens in /usr/local/anaconda3/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (2.0.8)\n",
      "Requirement already satisfied: pure-eval in /usr/local/anaconda3/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: executing in /usr/local/anaconda3/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/anaconda3/lib/python3.8/site-packages (from sympy->onnxruntime->-r requirements.txt (line 5)) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 07:55:23.963903: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import io, os, shutil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tflite\n",
    "from pytorch2keras import pytorch_to_keras\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pytorch_to_keras_model(pytorch_model, input_shape) -> tf.keras.Model:\n",
    "    input_np = np.random.uniform(0, 1, tuple([ 1 ]) + input_shape)\n",
    "    input_var = Variable(torch.FloatTensor(input_np))\n",
    "\n",
    "    return pytorch_to_keras(\n",
    "        pytorch_model,\n",
    "        input_var,\n",
    "        [input_shape],\n",
    "        verbose=True,\n",
    "        name_policy='short'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PyTorch Model\n",
    "For this example, we use mobilenet_v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "# Switch the model to eval mode\n",
    "pytorch_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run Inference on PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-27 07:55:41--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10472 (10K) [text/plain]\n",
      "Saving to: ‘imagenet_classes.txt.8’\n",
      "\n",
      "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-03-27 07:55:41 (13.9 MB/s) - ‘imagenet_classes.txt.8’ saved [10472/10472]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download an image to test against\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# Download Image Labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We will test and train with these params\n",
    "batch_size = 1\n",
    "channels = 3\n",
    "height = 224\n",
    "width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Open testing image\n",
    "input_image = Image.open(filename)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(height),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Note Pytorch is BCHW\n",
    "input_tensor = preprocess(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed : 0.8303043246269226\n",
      "Pomeranian : 0.06988773494958878\n",
      "keeshond : 0.012964080087840557\n",
      "collie : 0.010797776281833649\n",
      "Great Pyrenees : 0.009886783547699451\n"
     ]
    }
   ],
   "source": [
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = pytorch_model(input_batch)\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "# Show top categories per image\n",
    "vals, idxs = torch.topk(probabilities, 5)\n",
    "pytorch_results = [(categories[idx], prob) for (idx, prob) in zip(idxs.tolist(), vals.tolist())]\n",
    "for cat, prob in  pytorch_results:\n",
    "    print(cat, ':', prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Name policy isn't supported now.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[torch.Size([3, 224, 224])]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight classifier.1.weight with shape (1000, 1280).\n",
      "DEBUG:onnx2keras:Found weight classifier.1.bias with shape (1000,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_538 with shape (32, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_539 with shape (32,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_541 with shape (32, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_542 with shape (32,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_544 with shape (16, 32, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_545 with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_547 with shape (96, 16, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_548 with shape (96,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_550 with shape (96, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_551 with shape (96,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_553 with shape (24, 96, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_554 with shape (24,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_556 with shape (144, 24, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_557 with shape (144,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_559 with shape (144, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_560 with shape (144,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_562 with shape (24, 144, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_563 with shape (24,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_565 with shape (144, 24, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_566 with shape (144,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_568 with shape (144, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_569 with shape (144,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_571 with shape (32, 144, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_572 with shape (32,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_574 with shape (192, 32, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_575 with shape (192,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_577 with shape (192, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_578 with shape (192,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_580 with shape (32, 192, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_581 with shape (32,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_583 with shape (192, 32, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_584 with shape (192,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_586 with shape (192, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_587 with shape (192,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_589 with shape (32, 192, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_590 with shape (32,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_592 with shape (192, 32, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_593 with shape (192,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_595 with shape (192, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_596 with shape (192,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_598 with shape (64, 192, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_599 with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_601 with shape (384, 64, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_602 with shape (384,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_604 with shape (384, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_605 with shape (384,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_607 with shape (64, 384, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_608 with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_610 with shape (384, 64, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_611 with shape (384,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_613 with shape (384, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_614 with shape (384,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_616 with shape (64, 384, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_617 with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_619 with shape (384, 64, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_620 with shape (384,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_622 with shape (384, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_623 with shape (384,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_625 with shape (64, 384, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_626 with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_628 with shape (384, 64, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_629 with shape (384,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_631 with shape (384, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_632 with shape (384,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_634 with shape (96, 384, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_635 with shape (96,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_637 with shape (576, 96, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_638 with shape (576,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_640 with shape (576, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_641 with shape (576,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_643 with shape (96, 576, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_644 with shape (96,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_646 with shape (576, 96, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_647 with shape (576,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_649 with shape (576, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_650 with shape (576,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_652 with shape (96, 576, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_653 with shape (96,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_655 with shape (576, 96, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_656 with shape (576,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_658 with shape (576, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_659 with shape (576,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_661 with shape (160, 576, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_662 with shape (160,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_664 with shape (960, 160, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_665 with shape (960,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_667 with shape (960, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_668 with shape (960,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_670 with shape (160, 960, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_671 with shape (160,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_673 with shape (960, 160, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_674 with shape (960,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_676 with shape (960, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_677 with shape (960,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_679 with shape (160, 960, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_680 with shape (160,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_682 with shape (960, 160, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_683 with shape (960,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_685 with shape (960, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_686 with shape (960,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_688 with shape (320, 960, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_689 with shape (320,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_691 with shape (1280, 320, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_692 with shape (1280,).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape torch.Size([3, 224, 224])\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: input.4\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [2, 2], 'change_ordering': False, 'name_policy': 'short'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name onnx::Conv_538).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name onnx::Conv_539).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 32, 112, 112), dtype=tf.float32, name=None), name='input.4/BiasAdd:0', description=\"created by layer 'input.4'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: onnx::Clip_317\n",
      "DEBUG:onnx2keras:node_params: {'value': array(0., dtype=float32), 'change_ordering': False, 'name_policy': 'short'}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: onnx::Clip_318\n",
      "DEBUG:onnx2keras:node_params: {'value': array(6., dtype=float32), 'change_ordering': False, 'name_policy': 'short'}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Clip\n",
      "DEBUG:onnx2keras:node_name: onnx::Conv_319\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': 'short'}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input_0 : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n",
      "      %classifier.1.weight : Float(1000, 1280, strides=[1280, 1], requires_grad=1, device=cpu),\n",
      "      %classifier.1.bias : Float(1000, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::Conv_538 : Float(32, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_539 : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_541 : Float(32, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_542 : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_544 : Float(16, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_545 : Float(16, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_547 : Float(96, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_548 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_550 : Float(96, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_551 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_553 : Float(24, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_554 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_556 : Float(144, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_557 : Float(144, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_559 : Float(144, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_560 : Float(144, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_562 : Float(24, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_563 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_565 : Float(144, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_566 : Float(144, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_568 : Float(144, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_569 : Float(144, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_571 : Float(32, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_572 : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_574 : Float(192, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_575 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_577 : Float(192, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_578 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_580 : Float(32, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_581 : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_583 : Float(192, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_584 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_586 : Float(192, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_587 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_589 : Float(32, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_590 : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_592 : Float(192, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_593 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_595 : Float(192, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_596 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_598 : Float(64, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_599 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_601 : Float(384, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_602 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_604 : Float(384, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_605 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_607 : Float(64, 384, 1, 1, strides=[384, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_608 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_610 : Float(384, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_611 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_613 : Float(384, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_614 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_616 : Float(64, 384, 1, 1, strides=[384, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_617 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_619 : Float(384, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_620 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_622 : Float(384, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_623 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_625 : Float(64, 384, 1, 1, strides=[384, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_626 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_628 : Float(384, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_629 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_631 : Float(384, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_632 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_634 : Float(96, 384, 1, 1, strides=[384, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_635 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_637 : Float(576, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_638 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_640 : Float(576, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_641 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_643 : Float(96, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_644 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_646 : Float(576, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_647 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_649 : Float(576, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_650 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_652 : Float(96, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_653 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_655 : Float(576, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_656 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_658 : Float(576, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_659 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_661 : Float(160, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_662 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_664 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_665 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_667 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_668 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_670 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_671 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_673 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_674 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_676 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_677 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_679 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_680 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_682 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_683 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_685 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_686 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_688 : Float(320, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_689 : Float(320, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_691 : Float(1280, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_692 : Float(1280, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %input.4 : Float(1, 32, 112, 112, strides=[401408, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"Conv_0\"](%input_0, %onnx::Conv_538, %onnx::Conv_539) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_317 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_1\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_318 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_2\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_319 : Float(1, 32, 112, 112, strides=[401408, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_3\"](%input.4, %onnx::Clip_317, %onnx::Clip_318) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.12 : Float(1, 32, 112, 112, strides=[401408, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_4\"](%onnx::Conv_319, %onnx::Conv_541, %onnx::Conv_542) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_322 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_5\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_323 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_6\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_324 : Float(1, 32, 112, 112, strides=[401408, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_7\"](%input.12, %onnx::Clip_322, %onnx::Clip_323) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.20 : Float(1, 16, 112, 112, strides=[200704, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_8\"](%onnx::Conv_324, %onnx::Conv_544, %onnx::Conv_545) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.28 : Float(1, 96, 112, 112, strides=[1204224, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_9\"](%input.20, %onnx::Conv_547, %onnx::Conv_548) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_329 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_10\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_330 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_11\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_331 : Float(1, 96, 112, 112, strides=[1204224, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_12\"](%input.28, %onnx::Clip_329, %onnx::Clip_330) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.36 : Float(1, 96, 56, 56, strides=[301056, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=96, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"Conv_13\"](%onnx::Conv_331, %onnx::Conv_550, %onnx::Conv_551) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_334 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_14\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_335 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_15\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_336 : Float(1, 96, 56, 56, strides=[301056, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_16\"](%input.36, %onnx::Clip_334, %onnx::Clip_335) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.44 : Float(1, 24, 56, 56, strides=[75264, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_17\"](%onnx::Conv_336, %onnx::Conv_553, %onnx::Conv_554) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.52 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_18\"](%input.44, %onnx::Conv_556, %onnx::Conv_557) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_341 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_19\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_342 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_20\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_343 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_21\"](%input.52, %onnx::Clip_341, %onnx::Clip_342) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.60 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_22\"](%onnx::Conv_343, %onnx::Conv_559, %onnx::Conv_560) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_346 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_23\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_347 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_24\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_348 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_25\"](%input.60, %onnx::Clip_346, %onnx::Clip_347) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Add_561 : Float(1, 24, 56, 56, strides=[75264, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_26\"](%onnx::Conv_348, %onnx::Conv_562, %onnx::Conv_563) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.68 : Float(1, 24, 56, 56, strides=[75264, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_27\"](%input.44, %onnx::Add_561) # /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/mobilenetv2.py:98:0\n",
      "  %input.76 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_28\"](%input.68, %onnx::Conv_565, %onnx::Conv_566) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_354 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_29\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_355 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_30\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_356 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_31\"](%input.76, %onnx::Clip_354, %onnx::Clip_355) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.84 : Float(1, 144, 28, 28, strides=[112896, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"Conv_32\"](%onnx::Conv_356, %onnx::Conv_568, %onnx::Conv_569) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_359 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_33\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_360 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_34\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_361 : Float(1, 144, 28, 28, strides=[112896, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_35\"](%input.84, %onnx::Clip_359, %onnx::Clip_360) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.92 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_36\"](%onnx::Conv_361, %onnx::Conv_571, %onnx::Conv_572) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.100 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_37\"](%input.92, %onnx::Conv_574, %onnx::Conv_575) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_366 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_38\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_367 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_39\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_368 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_40\"](%input.100, %onnx::Clip_366, %onnx::Clip_367) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.108 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_41\"](%onnx::Conv_368, %onnx::Conv_577, %onnx::Conv_578) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_371 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_42\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_372 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_43\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_373 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_44\"](%input.108, %onnx::Clip_371, %onnx::Clip_372) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Add_579 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_45\"](%onnx::Conv_373, %onnx::Conv_580, %onnx::Conv_581) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.116 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_46\"](%input.92, %onnx::Add_579) # /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/mobilenetv2.py:98:0\n",
      "  %input.124 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_47\"](%input.116, %onnx::Conv_583, %onnx::Conv_584) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_379 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_48\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_380 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_49\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_381 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_50\"](%input.124, %onnx::Clip_379, %onnx::Clip_380) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.132 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_51\"](%onnx::Conv_381, %onnx::Conv_586, %onnx::Conv_587) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_384 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_52\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_385 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_53\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_386 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_54\"](%input.132, %onnx::Clip_384, %onnx::Clip_385) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Add_588 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_55\"](%onnx::Conv_386, %onnx::Conv_589, %onnx::Conv_590) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.140 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_56\"](%input.116, %onnx::Add_588) # /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/mobilenetv2.py:98:0\n",
      "  %input.148 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_57\"](%input.140, %onnx::Conv_592, %onnx::Conv_593) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_392 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_58\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_393 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_59\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_394 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_60\"](%input.148, %onnx::Clip_392, %onnx::Clip_393) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.156 : Float(1, 192, 14, 14, strides=[37632, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"Conv_61\"](%onnx::Conv_394, %onnx::Conv_595, %onnx::Conv_596) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_397 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_62\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_398 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_63\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_399 : Float(1, 192, 14, 14, strides=[37632, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_64\"](%input.156, %onnx::Clip_397, %onnx::Clip_398) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.164 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_65\"](%onnx::Conv_399, %onnx::Conv_598, %onnx::Conv_599) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.172 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_66\"](%input.164, %onnx::Conv_601, %onnx::Conv_602) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_404 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_67\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_405 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_68\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_406 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_69\"](%input.172, %onnx::Clip_404, %onnx::Clip_405) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.180 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_70\"](%onnx::Conv_406, %onnx::Conv_604, %onnx::Conv_605) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_409 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_71\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_410 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_72\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_411 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_73\"](%input.180, %onnx::Clip_409, %onnx::Clip_410) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Add_606 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_74\"](%onnx::Conv_411, %onnx::Conv_607, %onnx::Conv_608) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.188 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_75\"](%input.164, %onnx::Add_606) # /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/mobilenetv2.py:98:0\n",
      "  %input.196 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_76\"](%input.188, %onnx::Conv_610, %onnx::Conv_611) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_417 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_77\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_418 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_78\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_419 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_79\"](%input.196, %onnx::Clip_417, %onnx::Clip_418) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.204 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_80\"](%onnx::Conv_419, %onnx::Conv_613, %onnx::Conv_614) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_422 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_81\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_423 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_82\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_424 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_83\"](%input.204, %onnx::Clip_422, %onnx::Clip_423) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Add_615 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_84\"](%onnx::Conv_424, %onnx::Conv_616, %onnx::Conv_617) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.212 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_85\"](%input.188, %onnx::Add_615) # /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/mobilenetv2.py:98:0\n",
      "  %input.220 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_86\"](%input.212, %onnx::Conv_619, %onnx::Conv_620) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_430 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_87\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_431 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_88\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_432 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_89\"](%input.220, %onnx::Clip_430, %onnx::Clip_431) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.228 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_90\"](%onnx::Conv_432, %onnx::Conv_622, %onnx::Conv_623) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_435 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_91\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_436 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_92\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_437 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_93\"](%input.228, %onnx::Clip_435, %onnx::Clip_436) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Add_624 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_94\"](%onnx::Conv_437, %onnx::Conv_625, %onnx::Conv_626) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.236 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_95\"](%input.212, %onnx::Add_624) # /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/mobilenetv2.py:98:0\n",
      "  %input.244 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_96\"](%input.236, %onnx::Conv_628, %onnx::Conv_629) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_443 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_97\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_444 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_98\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_445 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_99\"](%input.244, %onnx::Clip_443, %onnx::Clip_444) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.252 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_100\"](%onnx::Conv_445, %onnx::Conv_631, %onnx::Conv_632) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_448 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_101\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_449 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_102\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_450 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_103\"](%input.252, %onnx::Clip_448, %onnx::Clip_449) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.260 : Float(1, 96, 14, 14, strides=[18816, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_104\"](%onnx::Conv_450, %onnx::Conv_634, %onnx::Conv_635) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.268 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_105\"](%input.260, %onnx::Conv_637, %onnx::Conv_638) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_455 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_106\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_456 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_107\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_457 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_108\"](%input.268, %onnx::Clip_455, %onnx::Clip_456) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.276 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_109\"](%onnx::Conv_457, %onnx::Conv_640, %onnx::Conv_641) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_460 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_110\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_461 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_111\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_462 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_112\"](%input.276, %onnx::Clip_460, %onnx::Clip_461) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Add_642 : Float(1, 96, 14, 14, strides=[18816, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_113\"](%onnx::Conv_462, %onnx::Conv_643, %onnx::Conv_644) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.284 : Float(1, 96, 14, 14, strides=[18816, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_114\"](%input.260, %onnx::Add_642) # /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/mobilenetv2.py:98:0\n",
      "  %input.292 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_115\"](%input.284, %onnx::Conv_646, %onnx::Conv_647) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_468 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_116\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_469 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_117\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_470 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_118\"](%input.292, %onnx::Clip_468, %onnx::Clip_469) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.300 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_119\"](%onnx::Conv_470, %onnx::Conv_649, %onnx::Conv_650) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_473 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_120\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_474 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_121\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_475 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_122\"](%input.300, %onnx::Clip_473, %onnx::Clip_474) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Add_651 : Float(1, 96, 14, 14, strides=[18816, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_123\"](%onnx::Conv_475, %onnx::Conv_652, %onnx::Conv_653) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.308 : Float(1, 96, 14, 14, strides=[18816, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_124\"](%input.284, %onnx::Add_651) # /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/mobilenetv2.py:98:0\n",
      "  %input.316 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_125\"](%input.308, %onnx::Conv_655, %onnx::Conv_656) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_481 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_126\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_482 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_127\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_483 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_128\"](%input.316, %onnx::Clip_481, %onnx::Clip_482) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.324 : Float(1, 576, 7, 7, strides=[28224, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"Conv_129\"](%onnx::Conv_483, %onnx::Conv_658, %onnx::Conv_659) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_486 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_130\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_487 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_131\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_488 : Float(1, 576, 7, 7, strides=[28224, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_132\"](%input.324, %onnx::Clip_486, %onnx::Clip_487) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.332 : Float(1, 160, 7, 7, strides=[7840, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_133\"](%onnx::Conv_488, %onnx::Conv_661, %onnx::Conv_662) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.340 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_134\"](%input.332, %onnx::Conv_664, %onnx::Conv_665) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_493 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_135\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_494 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_136\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_495 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_137\"](%input.340, %onnx::Clip_493, %onnx::Clip_494) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.348 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_138\"](%onnx::Conv_495, %onnx::Conv_667, %onnx::Conv_668) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_498 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_139\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_499 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_140\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_500 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_141\"](%input.348, %onnx::Clip_498, %onnx::Clip_499) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Add_669 : Float(1, 160, 7, 7, strides=[7840, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_142\"](%onnx::Conv_500, %onnx::Conv_670, %onnx::Conv_671) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.356 : Float(1, 160, 7, 7, strides=[7840, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_143\"](%input.332, %onnx::Add_669) # /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/mobilenetv2.py:98:0\n",
      "  %input.364 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_144\"](%input.356, %onnx::Conv_673, %onnx::Conv_674) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_506 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_145\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_507 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_146\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_508 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_147\"](%input.364, %onnx::Clip_506, %onnx::Clip_507) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.372 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_148\"](%onnx::Conv_508, %onnx::Conv_676, %onnx::Conv_677) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_511 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_149\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_512 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_150\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_513 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_151\"](%input.372, %onnx::Clip_511, %onnx::Clip_512) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Add_678 : Float(1, 160, 7, 7, strides=[7840, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_152\"](%onnx::Conv_513, %onnx::Conv_679, %onnx::Conv_680) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.380 : Float(1, 160, 7, 7, strides=[7840, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_153\"](%input.356, %onnx::Add_678) # /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/mobilenetv2.py:98:0\n",
      "  %input.388 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_154\"](%input.380, %onnx::Conv_682, %onnx::Conv_683) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_519 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_155\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_520 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_156\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_521 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_157\"](%input.388, %onnx::Clip_519, %onnx::Clip_520) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.396 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_158\"](%onnx::Conv_521, %onnx::Conv_685, %onnx::Conv_686) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_524 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_159\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_525 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_160\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Conv_526 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_161\"](%input.396, %onnx::Clip_524, %onnx::Clip_525) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %input.404 : Float(1, 320, 7, 7, strides=[15680, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_162\"](%onnx::Conv_526, %onnx::Conv_688, %onnx::Conv_689) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %input.412 : Float(1, 1280, 7, 7, strides=[62720, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_163\"](%input.404, %onnx::Conv_691, %onnx::Conv_692) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Clip_531 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_164\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Clip_532 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"Constant_165\"]() # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::GlobalAveragePool_533 : Float(1, 1280, 7, 7, strides=[62720, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[onnx_name=\"Clip_166\"](%input.412, %onnx::Clip_531, %onnx::Clip_532) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1506:0\n",
      "  %onnx::Flatten_534 : Float(1, 1280, 1, 1, strides=[1280, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool[onnx_name=\"GlobalAveragePool_167\"](%onnx::GlobalAveragePool_533) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1214:0\n",
      "  %input.416 : Float(1, 1280, strides=[1280, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1, onnx_name=\"Flatten_168\"](%onnx::Flatten_534) # /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/mobilenetv2.py:195:0\n",
      "  %output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"Gemm_169\"](%input.416, %classifier.1.weight, %classifier.1.bias) # /usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Check input 0 (name input.4).\n",
      "DEBUG:onnx2keras:Check input 1 (name onnx::Clip_317).\n",
      "DEBUG:onnx2keras:Check input 2 (name onnx::Clip_318).\n",
      "DEBUG:onnx2keras:... found all, continue\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m keras_model \u001b[38;5;241m=\u001b[39m \u001b[43mpytorch_to_keras_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpytorch_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [3], line 5\u001b[0m, in \u001b[0;36mpytorch_to_keras_model\u001b[0;34m(pytorch_model, input_shape)\u001b[0m\n\u001b[1;32m      2\u001b[0m input_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mtuple\u001b[39m([ \u001b[38;5;241m1\u001b[39m ]) \u001b[38;5;241m+\u001b[39m input_shape)\n\u001b[1;32m      3\u001b[0m input_var \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mFloatTensor(input_np))\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpytorch_to_keras\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpytorch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pytorch2keras/converter.py:72\u001b[0m, in \u001b[0;36mpytorch_to_keras\u001b[0;34m(model, args, input_shapes, change_ordering, verbose, name_policy, do_constant_folding)\u001b[0m\n\u001b[1;32m     69\u001b[0m stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     70\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mload(stream)\n\u001b[0;32m---> 72\u001b[0m k_model \u001b[38;5;241m=\u001b[39m \u001b[43monnx_to_keras\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchange_ordering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchange_ordering\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m k_model\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/onnx2keras/converter.py:175\u001b[0m, in \u001b[0;36monnx_to_keras\u001b[0;34m(onnx_model, input_names, input_shapes, name_policy, verbose, change_ordering)\u001b[0m\n\u001b[1;32m    172\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m... found all, continue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    174\u001b[0m keras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mset_image_data_format(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_first\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m \u001b[43mAVAILABLE_CONVERTERS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_funcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeras_names\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(keras_names, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    184\u001b[0m     keras_names \u001b[38;5;241m=\u001b[39m keras_names[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/onnx2keras/operation_layers.py:31\u001b[0m, in \u001b[0;36mconvert_clip\u001b[0;34m(node, params, layers, lambda_func, node_name, keras_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMore than 1 input for clip layer.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m input_0 \u001b[38;5;241m=\u001b[39m ensure_tf_type(layers[node\u001b[38;5;241m.\u001b[39minput[\u001b[38;5;241m0\u001b[39m]], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_const\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m keras_name)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     32\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing ReLU(\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m) instead of clip\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     33\u001b[0m     layer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mReLU(max_value\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m], name\u001b[38;5;241m=\u001b[39mkeras_name)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'min'"
     ]
    }
   ],
   "source": [
    "keras_model = pytorch_to_keras_model(pytorch_model, input_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Convert to tflite\n",
    "Following method from [keras_to_xcore.ipynb](https://colab.research.google.com/github/xmos/ai_tools/blob/develop/docs/notebooks/keras_to_xcore.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Representative Dataset\n",
    "To convert a model into to a TFLite flatbuffer, a representative dataset is required to help in quantisation. Refer to [Converting a keras model into an xcore optimised tflite model](https://colab.research.google.com/github/xmos/ai_tools/blob/develop/docs/notebooks/keras_to_xcore.ipynb) for more details on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We will use the imagenette dataset(326MB)\n",
    "!mkdir ./imagenet-dataset\n",
    "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz -O ./imagenet-dataset/imagenette2-320.tgz\n",
    "!tar -xf ./imagenet-dataset/imagenette2-320.tgz -C ./imagenet-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "all_files = glob.glob(os.path.join(\"./imagenet-dataset/\", '**/*.JPEG'), recursive=True)\n",
    "\n",
    "# Randomly select a subset of images, let's just use 1k for speed\n",
    "sampled_files = random.sample(all_files, 1000)\n",
    "\n",
    "def representative_dataset():\n",
    "\n",
    "    # Iterate over the sampled images and preprocess them\n",
    "    for image_path in sampled_files:\n",
    "        pil_image = Image.open(image_path).convert(\"RGB\")\n",
    "        pytorch_tensor = preprocess(pil_image).unsqueeze(0)\n",
    "        img_array_np = pytorch_tensor.numpy()\n",
    "\n",
    "        #swap the axes to BHWC(tf) from BCHW(pytorch)\n",
    "        img_array_np = np.transpose( img_array_np, [0, 2, 3, 1])\n",
    "        yield [img_array_np]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now do the conversion to int8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(\u001b[43mkeras_model\u001b[49m)\n\u001b[1;32m      5\u001b[0m converter\u001b[38;5;241m.\u001b[39moptimizations \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mOptimize\u001b[38;5;241m.\u001b[39mDEFAULT]\n\u001b[1;32m      6\u001b[0m converter\u001b[38;5;241m.\u001b[39mrepresentative_dataset \u001b[38;5;241m=\u001b[39m representative_dataset\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Now do the conversion to int8\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.float32 \n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "tflite_int8_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "tflite_int8_model_path = 'mobilenet_v2.tflite'\n",
    "with open(tflite_int8_model_path, 'wb') as f:\n",
    "  f.write(tflite_int8_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfl_interpreter = tf.lite.Interpreter(model_path=tflite_int8_model_path)\n",
    "tfl_interpreter.allocate_tensors()\n",
    "\n",
    "tfl_input_details = tfl_interpreter.get_input_details()\n",
    "tfl_output_details = tfl_interpreter.get_output_details()\n",
    "\n",
    "# Convert PyTorch Input Tensor into Numpy Matrix and Reshape for TensorFlow\n",
    "tfl_interpreter.set_tensor(tfl_input_details[0]['index'], tf_input_data)\n",
    "tfl_interpreter.invoke()\n",
    "\n",
    "tfl_output_data = tfl_interpreter.get_tensor(tfl_output_details[0]['index'])\n",
    "\n",
    "probs = softmax(tfl_output_data[0])\n",
    "data = zip(range(len(probs)), probs)\n",
    "tfl_int8_results = [(categories[idx], prob) for (idx, prob) in sorted(data, key=lambda x: x[1], reverse=True)[:5]]\n",
    "for cat, prob in  tfl_int8_results:\n",
    "    print(cat, ':', prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
