{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c42ac65",
   "metadata": {},
   "source": [
    "# Converting PyTorch to TensorFlow Lite for xCORE Using ONNX\n",
    "\n",
    "ONNX is an open format built to represent machine learning models. We can convert from PyTorch to ONNX, then from ONNX to TensorFlow, then from TensorFlow to TensorFlow Lite, and finally, run it through xformer to optimise it for xCORE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45a1445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in /usr/local/anaconda3/lib/python3.8/site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/anaconda3/lib/python3.8/site-packages (from torch) (4.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow in /usr/local/anaconda3/lib/python3.8/site-packages (2.12.0rc0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.51.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0rc0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.12.0rc1)\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (20.9)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.22.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: jax>=0.3.15 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0rc0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.12.0rc0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow) (1.6.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (4.11.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnx in /usr/local/anaconda3/lib/python3.8/site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx) (1.22.4)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx) (4.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: nvidia-pyindex in /usr/local/anaconda3/lib/python3.8/site-packages (1.0.9)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnx-graphsurgeon in /usr/local/anaconda3/lib/python3.8/site-packages (0.3.26)\n",
      "Requirement already satisfied: onnx in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx-graphsurgeon) (1.13.1)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx-graphsurgeon) (1.22.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx->onnx-graphsurgeon) (4.3.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx->onnx-graphsurgeon) (3.20.3)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: polygraphy in /usr/local/anaconda3/lib/python3.8/site-packages (0.44.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnxruntime in /usr/local/anaconda3/lib/python3.8/site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime) (1.22.4)\n",
      "Requirement already satisfied: sympy in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime) (1.8)\n",
      "Requirement already satisfied: protobuf in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime) (2.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime) (20.9)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from packaging->onnxruntime) (2.4.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/anaconda3/lib/python3.8/site-packages (from sympy->onnxruntime) (1.2.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnxsim in /usr/local/anaconda3/lib/python3.8/site-packages (0.4.17)\n",
      "Requirement already satisfied: rich in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxsim) (13.3.1)\n",
      "Requirement already satisfied: onnx in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxsim) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx->onnxsim) (4.3.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx->onnxsim) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx->onnxsim) (1.22.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->onnxsim) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->onnxsim) (2.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich->onnxsim) (0.1.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: simple_onnx_processing_tools in /usr/local/anaconda3/lib/python3.8/site-packages (1.1.16)\n",
      "Requirement already satisfied: sna4onnx>=1.0.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.6)\n",
      "Requirement already satisfied: sio4onnx>=1.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.2)\n",
      "Requirement already satisfied: soc4onnx>=1.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.2)\n",
      "Requirement already satisfied: json2onnx>=2.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (2.0.2)\n",
      "Requirement already satisfied: snc4onnx>=1.0.11 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.11)\n",
      "Requirement already satisfied: sor4onnx>=1.0.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.5)\n",
      "Requirement already satisfied: sit4onnx>=1.0.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.6)\n",
      "Requirement already satisfied: onnx2json>=2.0.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (2.0.4)\n",
      "Requirement already satisfied: sne4onnx>=1.0.11 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.11)\n",
      "Requirement already satisfied: sam4onnx>=1.0.13 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.13)\n",
      "Requirement already satisfied: svs4onnx>=1.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.0)\n",
      "Requirement already satisfied: sng4onnx>=1.0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.1)\n",
      "Requirement already satisfied: sog4onnx>=1.0.15 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.15)\n",
      "Requirement already satisfied: scc4onnx>=1.0.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.5)\n",
      "Requirement already satisfied: soa4onnx>=1.0.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.3)\n",
      "Requirement already satisfied: sbi4onnx>=1.0.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.4)\n",
      "Requirement already satisfied: scs4onnx>=1.0.18 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.18)\n",
      "Requirement already satisfied: ssc4onnx>=1.0.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.4)\n",
      "Requirement already satisfied: sde4onnx>=1.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.0)\n",
      "Requirement already satisfied: snd4onnx>=1.1.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.1.6)\n",
      "Requirement already satisfied: onnx2tf>=1.7.7 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.7.21)\n",
      "Requirement already satisfied: sod4onnx>=1.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.0)\n",
      "Requirement already satisfied: ssi4onnx>=1.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.2)\n",
      "Requirement already satisfied: sed4onnx>=1.0.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from simple_onnx_processing_tools) (1.0.5)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: protobuf==3.20.3 in /usr/local/anaconda3/lib/python3.8/site-packages (3.20.3)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: h5py==3.7 in /usr/local/anaconda3/lib/python3.8/site-packages (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from h5py==3.7) (1.22.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnx2tf in /usr/local/anaconda3/lib/python3.8/site-packages (1.7.21)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnx-tf in /usr/local/anaconda3/lib/python3.8/site-packages (1.10.0)\n",
      "Requirement already satisfied: onnx>=1.10.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx-tf) (1.13.1)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx-tf) (0.19.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx-tf) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx>=1.10.2->onnx-tf) (1.22.4)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx>=1.10.2->onnx-tf) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from onnx>=1.10.2->onnx-tf) (4.3.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow-addons->onnx-tf) (2.13.3)\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow-addons->onnx-tf) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from packaging->tensorflow-addons->onnx-tf) (2.4.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Requirement already satisfied: tensorflow-probability in /usr/local/anaconda3/lib/python3.8/site-packages (0.19.0)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow-probability) (1.22.4)\r\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow-probability) (1.6.0)\r\n",
      "Requirement already satisfied: absl-py in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow-probability) (1.0.0)\r\n",
      "Requirement already satisfied: gast>=0.3.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow-probability) (0.4.0)\r\n",
      "Requirement already satisfied: decorator in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow-probability) (5.0.6)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow-probability) (1.15.0)\r\n",
      "Requirement already satisfied: dm-tree in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow-probability) (0.1.8)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install tensorflow\n",
    "!pip install onnx\n",
    "!pip install nvidia-pyindex\n",
    "!pip install onnx-graphsurgeon\n",
    "!pip install polygraphy\n",
    "!pip install onnxruntime\n",
    "!pip install onnxsim\n",
    "!pip install simple_onnx_processing_tools\n",
    "!pip install protobuf==3.20.3\n",
    "!pip install h5py==3.7\n",
    "!pip install onnx2tf\n",
    "!pip install onnx-tf\n",
    "!pip install tensorflow-probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a90a93c",
   "metadata": {},
   "source": [
    "## Import PyTorch Model\n",
    "\n",
    "For this example, we use mobilenet_v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69af6e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/salmankhan/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92400780",
   "metadata": {},
   "source": [
    "### Run inference on model (to test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ac9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an image to test against\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17751687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-20 17:18:25--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10472 (10K) [text/plain]\n",
      "Saving to: ‘imagenet_classes.txt.1’\n",
      "\n",
      "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2023-03-20 17:18:26 (3.91 MB/s) - ‘imagenet_classes.txt.1’ saved [10472/10472]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download Image Labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477f8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64c20271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Samoyed', 0.8303042650222778), ('Pomeranian', 0.06988772749900818), ('keeshond', 0.012964067049324512), ('collie', 0.010797766037285328), ('Great Pyrenees', 0.009886772371828556)]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Open testing image\n",
    "input_image = Image.open(filename)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "# Show top categories per image\n",
    "vals, idxs = torch.topk(probabilities, 5)\n",
    "pytorch_results = [(categories[idx], prob) for (idx, prob) in zip(idxs.tolist(), vals.tolist())]\n",
    "print(pytorch_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9fde0a",
   "metadata": {},
   "source": [
    "## Convert to ONNX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a13b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "channels = 3\n",
    "height = 224\n",
    "width = 224\n",
    "\n",
    "sample_input = torch.rand((batch_size, channels, height, width))\n",
    "\n",
    "onnx_model_path = \"mobilenet_v2.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    sample_input,\n",
    "    onnx_model_path,\n",
    "    input_names=['image'],\n",
    "    output_names=['probabilities']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b1150",
   "metadata": {},
   "source": [
    "### Check ONNX Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "818c1a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Samoyed', 0.830305), ('Pomeranian', 0.06988746), ('keeshond', 0.012964004), ('collie', 0.010797733), ('Great Pyrenees', 0.009886744)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime \n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "def softmax(xs):\n",
    "    return np.exp(xs)/sum(np.exp(xs))\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(input_batch)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "data = zip(range(len(ort_outs[0][0])), softmax(ort_outs[0][0]))\n",
    "\n",
    "onnx_results = [(categories[idx], prob) for (idx, prob) in sorted(data, key=lambda x: x[1], reverse=True)[:5]]\n",
    "print(onnx_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1db68",
   "metadata": {},
   "source": [
    "## Representative Dataset\n",
    "\n",
    "To convert a model into to a TFLite flatbuffer, a representative dataset is required to help in quantisation. Refer to [Converting a keras model into an xcore optimised tflite model](https://colab.research.google.com/github/xmos/ai_tools/blob/develop/docs/notebooks/keras_to_xcore.ipynb) for more details on this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccffd66",
   "metadata": {},
   "source": [
    "#### Download & Extract Images from Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "488b0fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ./imagenet-dataset: File exists\n",
      "--2023-03-20 17:19:01--  https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.62.192, 54.231.170.56, 52.217.46.102, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.62.192|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 341663724 (326M) [application/x-tar]\n",
      "Saving to: ‘./imagenet-dataset/imagenette2-320.tgz’\n",
      "\n",
      "./imagenet-dataset/ 100%[===================>] 325.83M  1.45MB/s    in 3m 33s  \n",
      "\n",
      "2023-03-20 17:22:35 (1.53 MB/s) - ‘./imagenet-dataset/imagenette2-320.tgz’ saved [341663724/341663724]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./imagenet-dataset\n",
    "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz -O ./imagenet-dataset/imagenette2-320.tgz\n",
    "!tar -xf ./imagenet-dataset/imagenette2-320.tgz -C ./imagenet-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1780ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "def representative_dataset():\n",
    "    all_files = glob.glob(os.path.join(\"./imagenet-dataset/\", '**/*.JPEG'), recursive=True)\n",
    "    \n",
    "    # Randomly select a subset of images\n",
    "    sampled_files = random.sample(all_files, 100)\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Iterate over the sampled images and preprocess them\n",
    "    for image_path in sampled_files:\n",
    "        pil_image = Image.open(image_path).convert(\"RGB\")\n",
    "        pytorch_tensor = preprocess(pil_image).unsqueeze(0)\n",
    "        img_array = pytorch_tensor.numpy()\n",
    "        \n",
    "        reshaped = np.swapaxes(img_array, 1, 3)\n",
    "        yield [reshaped]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8277af37",
   "metadata": {},
   "source": [
    "## Using onnx-tensorflow (no longer maintained) / Not Currently Working\n",
    "\n",
    "Official ONNX package, however no longer officially maintained: https://github.com/onnx/onnx-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9712c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx_tf.backend import prepare\n",
    "\n",
    "# saved_model_path = \"saved_model\"\n",
    "# onnx_model = onnx.load(onnx_model_path)\n",
    "# prepare(onnx_model).export_graph(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b94d2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.representative_dataset = representative_dataset\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter.inference_input_type = tf.int8 \n",
    "# converter.inference_output_type = tf.int8\n",
    "\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the model.\n",
    "# tflite_model_path = 'mobilenet_v2.tflite'\n",
    "# with open(tflite_model_path, 'wb') as f:\n",
    "#   f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db0f492",
   "metadata": {},
   "source": [
    "## Using onnx2tf\n",
    "\n",
    "Using unofficial package: https://github.com/PINTO0309/onnx2tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5ad56",
   "metadata": {},
   "source": [
    "### Convert ONNX to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c593d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n"
     ]
    }
   ],
   "source": [
    "import onnx2tf\n",
    "\n",
    "keras_model = onnx2tf.convert(\n",
    "    input_onnx_file_path=onnx_model_path,\n",
    "    output_signaturedefs=True,\n",
    "    non_verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f3aa5",
   "metadata": {},
   "source": [
    "### Convert Keras to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b3e924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.float32 \n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "tflite_model_path = 'mobilenet_v2.tflite'\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c51156e",
   "metadata": {},
   "source": [
    "### Check it Worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3e82f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Great Pyrenees', 0.25053665), ('Samoyed', 0.11746472), ('Old English sheepdog', 0.08676046), ('Siberian husky', 0.08676046), ('Border collie', 0.07456401)]\n"
     ]
    }
   ],
   "source": [
    "tf_interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "tf_interpreter.allocate_tensors()\n",
    "\n",
    "tf_input_details = tf_interpreter.get_input_details()\n",
    "tf_output_details = tf_interpreter.get_output_details()\n",
    "\n",
    "# Convert PyTorch Input Tensor into Numpy Matrix and Reshape for TensorFlow\n",
    "# (Pytorch model expects C x H x W but TF expects H x W x C)\n",
    "tf_input_data = np.swapaxes(input_batch.detach().numpy(), 1, 3)\n",
    "\n",
    "tf_interpreter.set_tensor(tf_input_details[0]['index'], tf_input_data)\n",
    "tf_interpreter.invoke()\n",
    "\n",
    "tf_output_data = tf_interpreter.get_tensor(tf_output_details[0]['index'])\n",
    "data = zip(range(len(tf_output_data[0])), softmax(tf_output_data[0]))\n",
    "tf_results = [(categories[idx], prob) for (idx, prob) in sorted(data, key=lambda x: x[1], reverse=True)[:5]]\n",
    "\n",
    "print(tf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd9ae5b",
   "metadata": {},
   "source": [
    "# Analysing Models\n",
    "\n",
    "Defined below is a function to print out the operator counts of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc21b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "def get_operator_counts(model_content):\n",
    "    with io.StringIO() as buf, redirect_stdout(buf):\n",
    "        tf.lite.experimental.Analyzer.analyze(model_content=model_content)\n",
    "        model_structure = buf.getvalue()\n",
    "\n",
    "    operators = [op.strip().split(\" \")[1].split(\"(\")[0] for op in model_structure.split(\"\\n\") if \"Op#\" in op]\n",
    "    op_counts = {}\n",
    "    for operator in operators:\n",
    "        if operator in op_counts:\n",
    "            op_counts[operator] = op_counts[operator]+1\n",
    "        else:\n",
    "            op_counts[operator] = 1\n",
    "        \n",
    "    return (len(operators), op_counts)\n",
    "\n",
    "def print_operator_counts(model_content):\n",
    "    total_op_count, op_counts = get_operator_counts(model_content)\n",
    "    print(f\"{'Operator'.upper():<20} {'Count'.upper():>6}\")\n",
    "    print(\"-\"*20 + \" \" + \"-\"*6)\n",
    "    \n",
    "    for operator, count in op_counts.items():\n",
    "        print(f\"{operator.lower():<20} {count:>6}\")\n",
    "        \n",
    "    print(\"-\"*20 + \" \" + \"-\"*6)\n",
    "    print(f\"{'Total'.upper():<20} {total_op_count:>6}\")\n",
    "    print(\"-\"*20 + \" \" + \"-\"*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ecb085",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_operator_counts(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15cbde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
